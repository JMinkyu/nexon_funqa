{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime as dt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = [{'USER-Agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36'}]\n",
    "\n",
    "def call_site(page) :\n",
    "  url = f'https://arca.live/b/dunfa?p={page}'\n",
    "  response = requests.get(url)\n",
    "\n",
    "  if response.status_code != 200 :\n",
    "    print(f'API_call error : {response.status_code}')\n",
    "    return None\n",
    "  \n",
    "  soup = BeautifulSoup(response.content, 'html.parser')\n",
    "  return soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- requests 시도 403 오류로 인한 데이터 수집 불가\n",
    "- 찾아보니까 JS 챌린지라는 걸 넣어서 비정상적인 API 접근이 안된다고함.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selenium으로 돌리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install Selenium\n",
    "# !pip install webdriver-manager\n",
    "# !pip install undetected_chromedriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_content(user_content):\n",
    "    \n",
    "# 개시글 구현\n",
    "    for i in range(len(user_content)):\n",
    "        title = user_content[i].find('span', class_='title').text.strip()\n",
    "        nickname = user_content[i].select(\"span[data-filter]\")[0].text.strip()\n",
    "        title_num = user_content[i].find_all('span', class_=\"vcol col-id\")[0].text.strip()\n",
    "        title_time = user_content[i].select(\"time[datetime]\")[0].text\n",
    "        link = user_content[i].get('href')\n",
    "\n",
    "        # try-except 블록을 반복문 안으로 이동\n",
    "        try:\n",
    "            title_time = dt.datetime.strptime(title_time, \"%H:%M\")  # %M:%S가 아닌 %H:%M 사용\n",
    "            title_time = title_time.replace(year=now_time.year, month=now_time.month, day=now_time.day).strftime(\"%Y-%m-%d\")\n",
    "        except:\n",
    "            try:\n",
    "                title_time = dt.datetime.strptime(title_time, \"%Y.%m.%d\").strftime(\"%Y-%m-%d\")\n",
    "            except:\n",
    "                # 두 형식 모두 실패하면 원래 텍스트 유지\n",
    "                print(f\"날짜 형식 오류: {title_time}\")\n",
    "\n",
    "        ######################################\n",
    "        # 게시글 본문 크롤링 구현\n",
    "        post_url = f'https://arca.live{link}'\n",
    "        driver.get(post_url)\n",
    "\n",
    "        # 봇방지 프로그램 우회\n",
    "        time.sleep(random.uniform(5, 8))\n",
    "\n",
    "         # 게시글 본문이 로드될 때까지 대기\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "        wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, \"body\")))\n",
    "        html = driver.page_source\n",
    "        content_soup = BeautifulSoup(html, 'html.parser')\n",
    "        content = content_soup.select_one('div.fr-veiw article-content').text\n",
    "        #######################################################\n",
    "\n",
    "        # 데이터 축적\n",
    "        num_lst.append(title_num)\n",
    "        time_lst.append(title_time)\n",
    "        nickname_lst.append(nickname)\n",
    "        title_lst.append(title)\n",
    "        content_lst.append(content)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[158], line 49\u001b[0m\n\u001b[0;32m     46\u001b[0m soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(initial_html, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     47\u001b[0m user_content \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvrow column\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 49\u001b[0m preprocess_content(user_content) \u001b[38;5;66;03m# 게시글 전처리 진행행\u001b[39;00m\n\u001b[0;32m     51\u001b[0m driver\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m     53\u001b[0m test_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m : time_lst,\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum\u001b[39m\u001b[38;5;124m'\u001b[39m : num_lst,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m : content_lst\n\u001b[0;32m     59\u001b[0m })\n",
      "Cell \u001b[1;32mIn[157], line 35\u001b[0m, in \u001b[0;36mpreprocess_content\u001b[1;34m(user_content)\u001b[0m\n\u001b[0;32m     33\u001b[0m html \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mpage_source\n\u001b[0;32m     34\u001b[0m content_soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(html, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 35\u001b[0m content \u001b[38;5;241m=\u001b[39m content_soup\u001b[38;5;241m.\u001b[39mselect_one(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiv.fr-veiw article-content\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mtext\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m#######################################################\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# 데이터 축적\u001b[39;00m\n\u001b[0;32m     39\u001b[0m num_lst\u001b[38;5;241m.\u001b[39mappend(title_num)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# 웹드라이버 초기화\n",
    "options = uc.ChromeOptions()\n",
    "options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "options.add_argument(\"--disable-dev-shm-usage\")\n",
    "options.add_argument(\"--no-sandbox\")\n",
    "\n",
    "user_agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36'\n",
    "options.add_argument(f'--user-agent={user_agent}')\n",
    "\n",
    "driver = uc.Chrome(options=options)\n",
    "driver.execute_script(\"Object.defineProperty(navigator, 'webdriver', {get: () => undefined})\")\n",
    "\n",
    "\n",
    "# 웹페이지 열기\n",
    "driver.get(\"https://arca.live/b/dunfa\")\n",
    "\n",
    "# 봇방지 프로그램 우회\n",
    "time.sleep(random.uniform(5, 8))\n",
    "\n",
    "# Cloudflare 검사가 끝날떄까지 기다리기\n",
    "wait = WebDriverWait(driver, 10)\n",
    "wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, \"body\")))\n",
    "\n",
    "\n",
    "# 크롤링 로직\n",
    "initial_html = driver.page_source\n",
    "\n",
    "# 축적시킬 리스트\n",
    "num_lst = []\n",
    "time_lst = []\n",
    "nickname_lst = []\n",
    "title_lst = []\n",
    "content_lst = []\n",
    "\n",
    "# 게시글 크롤링 진행\n",
    "## 리스트에 자동으로 쌓임\n",
    "now_time = dt.datetime.now()\n",
    "soup = BeautifulSoup(initial_html, 'html.parser')\n",
    "user_content = soup.find_all('a', class_='vrow column')\n",
    "\n",
    "preprocess_content(user_content) # 게시글 전처리 진행행\n",
    "\n",
    "driver.close()\n",
    "\n",
    "test_df = pd.DataFrame({\n",
    "    'time' : time_lst,\n",
    "    'num' : num_lst,\n",
    "    'nickname' : nickname_lst,\n",
    "    'title' : title_lst,\n",
    "    'content' : content_lst\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'content_soup' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[159], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m content_soup\n",
      "\u001b[1;31mNameError\u001b[0m: name 'content_soup' is not defined"
     ]
    }
   ],
   "source": [
    "content_soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>num</th>\n",
       "      <th>nickname</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [time, num, nickname, title, content]\n",
       "Index: []"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.DataFrame({\n",
    "    'time' : time_lst,\n",
    "    'num' : num_lst,\n",
    "    'nickname' : nickname_lst,\n",
    "    'title' : title_lst,\n",
    "    'content' : content_lst\n",
    "})\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "상던 개편 진짜 개필수임\n",
      "번호\n",
      "*ㅁㅁ\n",
      "2025-04-09\n"
     ]
    }
   ],
   "source": [
    "now_time = dt.datetime.now()\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soup = BeautifulSoup(initial_html, 'html.parser')\n",
    "\n",
    "# 글 제목\n",
    "title = soup.find_all('span', class_ = 'title')[0].text.strip()\n",
    "\n",
    "# 유저 닉네임 수집\n",
    "nickname = soup.select(\"span[data-filter]\")[0].text.strip()\n",
    "\n",
    "# 작성글 번호\n",
    "title_num = soup.find_all('span', class_ =\"vcol col-id\")[0].text.strip()\n",
    "\n",
    "# 작성글\n",
    "title_time = soup.select(\"time[datetime]\")[0].text.strip()\n",
    "try :\n",
    "    title_time = dt.datetime.strptime(title_time, \"%M:%S\")\n",
    "    title_time = title_time.replace(year = now_time.year, month=now_time.month, day=now_time.day).strftime(\"%Y-%m-%d\")\n",
    "except :\n",
    "    title_time = dt.datetime.strptime(title_time, \"%Y.%m.%d\").strftime(\"%Y-%m-%d\")\n",
    "\n",
    "print(title)\n",
    "print(nickname)\n",
    "print(title_num)\n",
    "print(title_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(user_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:55 4206779 농설화 상던 개편 진짜 개필수임\n",
      "15:55 4206778 Idlinger 범위 vs 모든속도\n",
      "15:55 4206777 sky567 무키 밸런스 패치라도 좀 하지 답답하네\n",
      "15:55 4206776 Ryan_08 뉴비 지금 유입 가능함?\n",
      "15:55 4206775 셀리나 이번시즌은 던담순위가 잘안바뀌네\n",
      "15:54 4206774 나이알라 ㅈㄹ) 정화 태초셋 찍었다!\n",
      "15:54 4206773 mqm 딜러난 미쳤네\n",
      "15:54 4206772 Rusalka 수리비를 아끼는 법\n",
      "15:54 4206771 포커스샷 와 이새기들 악질이네\n",
      "15:54 4206770 노드왕 와 겜 오래한거같은데 아직도 4시밖에 안됐네\n",
      "15:54 4206769 후룰롤루 강림 진짜 줫나 어렵네\n",
      "15:54 4206768 Seaterror 오라 재판한다치면 10달은쓰나?\n",
      "15:53 4206767 퐁실한계란말이 아직까지도 베누스에서 에픽융합석을 못본 사람이 있음? ㅋㅋㅋㅋㅋㅋㅋㅋ\n",
      "15:53 4206766 ㅇㅅㄷ 하드빡세보이는대 제발무기좀뜨자 이제\n",
      "15:53 4206765 몬가 11증 븜  10증으로 내려봤음\n",
      "15:53 4206764 PMAR 던파티비 공략 없는거 총검사 가족사진만 없네\n",
      "15:52 4206763 ㅇㅇ 안개신 웃긴점\n",
      "15:52 4206762 아이유윤하 한달전으로 가서 일벨컷 30/400 컷이라 하면 차단당하나요\n",
      "15:52 4206761 사기리 브으음\n",
      "15:50 4206760 미마므 나는 이번에 크리쳐 갱신되도 ㄱㅊ다 생각함\n",
      "15:50 4206759 정하루 단델 좀 꼴리게 생기지 않음?\n",
      "15:49 4206758 heo0 완전 천천히 하나 올린다 생각하고\n",
      "15:49 4206757 비비고왕교자김치만두 본캐가 35일째 공회전중인데 그냥 부캐에다 계시나 써줄까\n",
      "15:49 4206756 호오후오훙아 베누스100클 하는 동안 엘리브 단 한번 봄\n",
      "15:48 4206755 Invok 피로도 대충쓰고 던담 딸깍중인데\n",
      "15:47 4206754 위즈 드랜이 체급이 생각보다 좋더라\n",
      "15:47 4206753 ㅇㅇ 복귀할랬는데 옛날계정 날아갔네\n",
      "15:47 4206752 사랑해엘리시아 유진 이 새기 뭐함????\n",
      "15:46 4206751 콘쓸려고가입함 본캐 고유 에픽 피감업글한거 존나 아까움 ㄹㅇ\n",
      "15:46 4206750 ReXian 좋아 배럭들 환요 흰구솔호수는 다했다\n",
      "15:45 4206749 사기리 와 몸매\n",
      "15:45 4206748 니샤아 태초 먹고 싶다\n",
      "15:45 4206747 쉽상땃쥐 베누스1단 깜보딜벞교\n",
      "15:44 4206746 월하 예비군 막ㄱ날 끝 15.57분전ㅋㅋㅋㅋㅋㅋ\n",
      "15:44 4206745 지현 딱권장 450이 어케 나옴 헛소리하지마셂....\n",
      "15:44 4206744 raradina 솔직히 메타몽 하나는 줬으면 좋겠다\n",
      "15:43 4206743 닌헷 베누스 5욕망 이면 모속40퍼네\n",
      "15:43 4206742 노드왕 아이시팔 아무리 랏벞이라해도 버퍼가 포탐을 아예 모르면 어케해\n",
      "15:43 4206741 PMAR 종숭이가 15배,50배도 들어가면 확정되나?\n",
      "15:43 4206740 ㅇㅇ 근디 레이드나오면 상던정돈 압축해줘야하지않나\n",
      "15:42 4206739 싹븜 장난하지말고 빨리 엘리브카드 가격좀 내려주세요\n",
      "15:42 4206738 ㅇㅇ 곰장연 걍 버퍼고유로 갈아타야겠다\n",
      "15:42 4206737 Ruru 아 집가서 던전파고하고싶어\n",
      "15:42 4206736 레드향 에쥬어랑 달잠호 사이에 상던 하나 만들어주면 좋겠다\n",
      "15:41 4206735 팝콘맛환타 0.1초경매\n"
     ]
    }
   ],
   "source": [
    "user_content = soup.find_all('a', class_ = 'vrow column')\n",
    "\n",
    "# title = user_content[0].find('span', class_ = 'title').text.strip()\n",
    "# nickname = user_content[0].select(\"span[data-filter]\")[0].text.strip()\n",
    "# title_num = user_content[0].find_all('span', class_ =\"vcol col-id\")[0].text.strip()\n",
    "# title_time = user_content[0].select(\"time[datetime]\")[0].text\n",
    "\n",
    "for i in range(len(user_content)) :\n",
    "  title = user_content[i].find('span', class_ = 'title').text.strip()\n",
    "  nickname = user_content[i].select(\"span[data-filter]\")[0].text.strip()\n",
    "  title_num = user_content[i].find_all('span', class_ =\"vcol col-id\")[0].text.strip()\n",
    "  title_time = user_content[i].select(\"time[datetime]\")[0].text\n",
    "  print(title_time, title_num, nickname, title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/b/dunfa/133604525?p=1'"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_content[0].get('href')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.select('a vrow.column')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
